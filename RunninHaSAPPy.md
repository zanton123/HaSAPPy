#Controlling the HaSAPPy workflow throught command scripts


The HaSAPPy analysis pipeline is controlled by a command script that is provided by the user (the LoadModule.txt file). All the parameters are collected by the INFOloads.py module and stored in an INFO object that organizes software scheduling and stores user defined parameters.
The file is subdivided in different sections marked by an identification number (0-9); each section is characterized by multiple input fields that are marked with a TAG `@1a)`, consisting of an `@`, the section number, a letter referring to the specific input field, and a `)`, after which user input can be entered on the same line:
```
@1A) <Operator name>
```

> **NOTE:** Avoid modifing the TAG, otherwise **INFOloads.py** will not parse the file correctly and fail to load parameters. Spaces between the TAG and the input are acceptable, but will not be accepted for PATH names.

This tutorial explains all sections of a HaSAPPy command script and illustrates the use of parameters to specify the workflow.
For this purpose, it will be assumed that all files are under a HaSAPPy folder within the user home directors, abbreviated as:

```
Users/User
```

A HaSAPPy command script is separated into 9 sections corresponding to the steps of data processing, analysis, and output customization.

## Section 0: Which analysis would you like to perform?
Select which step of the analysis to perform. Mark ‘Y’ to execute the corresponding step of the pipeline, 'N' else.

```
Trim adaptor and sequence quality selection     (fill up section 2):
@0A)n

Alignment and discharging Phix genome           (fill up section 3):
@0B)N	
Alignment to reference genome                   (fill up section 4):
@0C) y

Identification of Independent Insertions (I.I.) (fill up section 5):
@0D)    Y
Classification of I.I. in genes			         (fill up section 6):
@0E) Y

Comparison of different experiments 		     (fill up section 7):
@0F) Y

Generate Tables summarising analysis results 	  (fill up section 8):
@0G)Y

Visualise insertions by genes representation 	  (fill up section 9):
@0H) N
```

Spcifying a `y` or `Y` after a TAG will include the specified process into the data analysis workflow. `N` or `n` prevents the step from being scheduled. Note: Some steps depend on output of other modules and it is the user's responsibility to ensure that dependencies are met by scheduling consecutive processing steps.

> **IMPORTANT:** HaSAPPy will ignore any information in sections that were excluded from scheduling including any errors.

In the pipeline multiple modules can be processed if they are performed in succession: the following module needs information generated by the previous one during the analysis and these information can not be provided by the user (Alignment and discharging PhiX genome is an exception).

## Section 1: General Information

A user name can be provided that will be recorded along with the run information (this field is optional):

```
Operator Name: 
@1A) Anton Wutz
```

The folder for all files produced by an analysis workflow can be specified through a user selected PATH in the filesystem. The PATH must exist i the file system and point to the top-level folder where the folder structure for HaSAPPy intermedidiary and output files will be stored. It is the responsibility of the user to ensure that enough storage capacity is available to store the entire set of data files, which can be significant depending on the scale of the project:

```
Storing location (provide a correct path):
@1B) /Users/User/HaSAPPy/experiments
```

The **INFOloads.py** module will generate the following folder structure for the analysis:

```
/Users/User/HaSAPPy/experiments/
│
├── *library*_yyyy-mm-dd
│   │
│   ├── graph
│   │   └── <graphic output of run>
│   └── raw
│       └── <intermediary files of data processing>
│
└── Analysis
    │
    ├── yyyy-mm-dd_info.txt
    │
    ├── graph
    │   └── <graphic output when specified>
    └── raw
        └── <data bases>
```

For each NGS read dataset analyzed a specific folder will be generated using as reference the library name provided by the user in the following section. If a similar folder already exists, HaSAPPy will request an alternative name for library name/destination. Output files from section 1 to section 6 will be written to this folder. The library_info.txt file records all information of the run and of the selected parameters.

Information and data obtained from section 7 to 9 are not referring to a particular library but instead to an analysis performed comparing multiple libraries. Data will be collected in the Analysis folder according to the date in which the analysis is performed. If a similar folder already exists, HaSAPPy will request an alternative name for analysis destination.


## Section 2: Trim Adaptor and Sequence quality selection

```
How many libraries do you want to analyse?:
@2A) 2
Are those libraries sequenced pair-end?:
@2B) N
```
	
The name of the library will be used as first attempt as name for folder generation and will be used as `tag` to generate file names of output and table headers for Group analysis. It is requested that the user selects a short and meaningful name that must not contain spaces:

> **IMPORTANT** Don’t use spaces in the name!!

```
Name of the libraries (add additional lines if necessary):
@2C) Exp1
@2C) Exp2
…
```

Specify the absolute PATH (from the system root `/`) to the NGS read files in FastQ format. It is important to specify the file paths in the same order as the corresponding names of the experiments in `@2C)`. Compressed files (`.fastq.gz`) can also be processed:
```
Location of input file 1 (add additional lines if necessary):
@2D) /Users/User/HaSAPPy/experiments/raw_data/file1.fastq
@2D) /Users/User/HaSAPPy/experiments/raw_data/file2.fastq
…
```

If **paired-end sequencing** is used alignment of read pairs should be performed. For this a second fastq file can be provided containing the second sequencing run.
> **IMPORTANT:** The order of file names must be the same as in  `@2C)` and  `@2D)` to ensure that HaSAPPy matches the correct read pairs and experiments:

```
Location of input file 2 (if pair-end) (add additional lines if necessary):
@2E)
@2E)
…
```

PCR amplification can lead to reads of a reduced length and consequently the NGS sequencing run might averlap the adaptor sequence on the other side. Provide the adaptor sequence that could be present at the end of the read for removal (on Illumina Sequencers the first sequence run can overlap the p7 adaptor and the second the p5 adaptor):
```
Adaptor p7 sequence (for trimming 3’ ends of sequence in file 1):
@2F) ATCTCGTATGCCGTCTTCTGCTT
Adaptor p5 sequence (for trimming 3’ ends of sequence in file 2):
@2G)
```

Base quality is reported in the FastQ read file. To eliminate low quality sequences from reads PreprocessReads scanns the read for low quality bases that fall below a threshold for `Initial bad quality QA value detected ‘@2H)’`. If the remainder of the read has an average base quality below a `Quality average limit of 3’end sequence ‘@2J)’`, trimming of the read at this position is performed leaving a shorter read of good base quality. If the remainder of the read has sufficiently high average base quality, a low quality position is tolerated and scanning of the remainder of the read proceeds. This ensures that a maximum of sequencing data is retained for data analysis but bad quality reads are eliminated. Reads that become too short after trimming are also discarded, whereby a threshold of 26 bases is used to select reads.
```
Quality selection parameters:
	Initial bad quality QA value detected:
	@2H)  20
	Quality average limit of 3’end sequence after the call of a bad quality base:
	@2J) 25
```

Intermediate files of data processing can take up a lot of storage space. HaSAPPy has an option to retain all files or to delete the files once they are no longer needed. Enter `N` in the following input field, if you don’t want the permanently store the output file generated. In this case the file will be used by the Align module and erased thereafter.
```
Would you like to store quality selected libraries (mark ‘Y’ or ’N’)?
@2K) N
```

## Section 3: Alignment and discharging PhiX genome

If NGS sequence libraries were spiked with PhiX control fragments removal of the corresponding PhiX reads is required. Provide the absolute PATH to the Phix genome index for Bowtie2. The file name of the index without file extension should be provided (see Bowtie2 reference):
```
Location of Phix reference genome:
@3A) /Users/User/HaSAPPy/reference/Phix/NCBI/1993-04-28/Sequence/BowtieIndex/genome
```

Mark `N` if you don’t want the permanently store the output read file that is generated. In this case the file will be used by the Align module and erased afterwards:
```
Would you like to store permanently Phix-cleaned files  (mark ‘Y’ or ’N’)?
@3B)
```

HaSAPPy provides the flexibility to start an analysis workflow with preprocessed read files in FastQ format. This facilitates the use of any tools for adaptor trimming. In this case, provide the FastQ files as the starting point of the analysis. Enter the name, read information, and absolute PATH of the Fastq files (the Fastq file must be decompressed):

> **NOTE:** HaSAPPy does not accept compressed FastQ files at this entry into the workflow!

```
!!!N.B. Compile the following section just if this is your starting point!!!
How many libraries do you want to analyse?:
@3C)
Are those libraries sequenced pair-end?:
@3D)	
Name of the libraries (add additional lines if necessary):
@3E)
@3E)
…
Location of input file 1(add additional lines if necessary):
@3F)
@3F)
…
Location of input file 2 (if pair-end) (add additional lines if necessary):
@3G)
@3G)
…
```

## Section 4: Alignment to the reference genome

For mapping reads to the reference genome (mouse or human, etc) HaSAPPy comes preconfigured for use of Bowtie2, NextGenMap (ngm), and nvBowtie. Enter the read alignment program you want to use for read mapping to the reference genome.
```
Alignment program to be used (bowtie2, nvBowtie, NextGenMap):
@4A) bowtie2
```
>**NOTE:** The selected read aligner must be installed on your system and reachable form the PATH.

Provide the absolute PATH of reference genome index for the selected read mapper. For bowtie2 and nvBowtie the path and file name of the genome index without file extension must be entered. For NextGenMap, provide the path to the genome sequence Fasta file (“xxxxx.fa” file):
```
Location of reference genome:
@4B) /Users/User/HaSAPPy/reference/Mus_musculus/UCSC/mm10/Sequence/BowtieIndex/genome
```

Enter `N` in the input field below, if you don’t want to permanently store the output file generated. In this case the file will be used by the IIdefinition module and erased afterwards:
```
Would you like to store permanently BAM aligned files  (mark ‘Y’ or ’N’)?
@4C)Y
```

If this is the first step in your workflow and this module is the starting point of the analysis, you should provide information on the name and properties of the NGS libraries and the corresponding Fastq files in the input fields below. This is particularly useful if tools from Illumina have been used for PhiX removal and adaptor trimming. It is possible to use preprocessed read files and specifying the Fastq files here.

> **NOTE:** If analysis starts here the Fastq file must be decompressed, HaSAPPy presently does not accept compressed formats at this step of the analysis.
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many libraries do you want to analyse?:
@4D)	
Are those libraries sequenced pair-end?:
@4E)	
Name of the library (add additional lines if necessary):
@4F)
@4F)
…
Location of input file 1(add additional lines if necessary):
@4G)
@4G)
…
Location of input file 2 (if pair-end) (add additional lines if necessary):
@4H)
@4H)
…
```

## Section 5: Identification of Independent Insertions (I.I.)

During the definition of Independent insertions, user can provide a minimal number of read count requested to define an insertion. This parameter can be used to reduce noise deriving from sequencing procedure, but can also affect library complexity and resolution (particularly in unselected libraries). An integer number should be provided. Default is ‘1’. 
```
Number of reads to define a I.I.:
@5A) 2
```

HaSAPPy provides the possibility to remove PCR-duplicates from the read count if libraries were sequenced in the pair-end mode (for details refer to HaSAPPy manual). If you activate this option duplicates and not pair-ends aligned reads will be discharged.
```
If pair-end libraries, do you want to remove PCR-duplicates (mark ‘Y’ or ’N’)?
@5B) N
```

For each read, alignment software supply a reliability value of the alignment to the reference genome. In this parameter the number of mismatches and match uniqueness is taken into account. Increasing the alignment fidelity parameter can help to reduce noise. Mark ‘Y’ if you want to activate this selection and provide an integer number as limit. Default is ‘0’. 
```
Do you want to indicate a level of alignment fidelity (mark ‘Y’ or ’N’):
@5C) Y
If level of alignment fidelity is requested, provide a limit number:
@5D) 5
```

If this module is the starting point of the analysis, you should supply information on the name and properties of the libraries and the SAM file referring to their alignment
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@5E)	
Are those libraries sequenced pair-end?:
@5F)	
Name of the library (add additional lines if necessary):
@5G)
@5G)
…
Location of input file 1(add additional lines if necessary):
@5H)
@5H)
…
```

## Section 6: Classification of I.I. in genes
To categorize I.I. according their location in genes, you are requested to provide the gene reference file created with the GeneReference_built.py module. The absolute PATH must be supplied
```
Location of gene reference:
@6A) Users/User/HaSAPPy/docs/GeneReference_Mouse-MM10.pkl
```

User can define which parameters should be collected during this process. Mark ‘Y’ or ‘N’ according to your needs. For details on parameter description refer to the HaSAPPy manual.
> **IMPORTANT** If at this step you are not selecting a parameter, this will not be stored and will not be available for the following steps of the analysis.

```
Type of parameters analysed (mark ‘Y’ or ’N’):
	Independent insertions (I.I.):
	@6B) Y
	Killing insertions (K.I.):
	@6C) Y
	Bias insertions:
	@6D) Y
	Reads:
	@6E) N
```

If this module is the starting point of the analysis, you should provide information on the name and properties of the libraries and the “../../*library*_dddd-mm-yy/raw/*library*.IIRawData.pkl” generated by the IIDefinition.py module
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@6F)	
Are those libraries sequenced pair-end?:
@6G)	
Name of the library (add additional lines if necessary):
@6H)
@6H)
…
Location of input file 1(add additional lines if necessary):
@6I)
@6I)
…
```

## Section 7: Comparison of different experiments
The GroupAnalysis.py module collects processed libraries from GeneDefinition.py module and according to user indications subdivides them in groups composed of several replicates. For all the parameters selected (II,KI,Bias,bias_FW,bias_RV,Reads) it calculates mean and standard deviation of the replicates. Groups are then compared respect to a reference group (indicated by the user) and fold difference, ttest and Outlier analysis are calculated.

Provide the number of groups present in your analysis. An integer number >= 2 is requested 
```
Number of groups to be analysed:
@7A) 3
```

The name of the reference group must be provided; table columns labelling will use this name for identification. Mean and standard deviation will be calculated BUT fold difference,ttest… will not be available for this group. In general, unselected libraries are used as reference.
```
Reference group name:
@7B) Unselected
```

Provide the names of the libraries present in the group. A list of library names subdivided by a ‘,’ is requested. Spaces between library names is managed by HaSAPPy. If this is not the starting point of the analysis, libraries name must correspond to the ones defined in the previous modules.
> You are not allowed to introduce new libraries produced in previous pipeline. In this case, generate a new pipeline starting from the GroupAnalysis.py module and introduce libraries used for the analysis in the ‘starting point’ tasks of this section.
```
Reference group data (provide the library names separated by a ‘,’ (ex. ‘lib1,lib2,lib3’)):
@7C) ctrl1 ,ctrl2, ctrl3
```

Provide the name of the analysed group. If you have several experimental conditions, multiple groups can be created. They will all be compared to the reference group. In each line provide the name of the independent group.
```
Other data group name(add additional lines if necessary):
@7D) Condition_A
@7D) Condition_B
…
```

As for the reference group, provide the libraries name corresponding to the group replicates. Pay attention that HaSAPPy aspects the same number of lists as the group number defined in the previous task. Correspondence of libraries to group is dependent on order of compilation
```
Other data group (provide the library names separated by a ‘,’ (ex. ‘lib1,lib2,lib3’))(add additional lines if necessary):
 @7E) ExpA_1, ExpA_2, ExpA_3
 @7E) ExpB_1, ExpB_2, ExpB_3
…
```

User can define which parameters should be analysed. Mark ‘Y’ or ‘N’ according to your needs. If a parameter was not collected during library generation (GeneDefinition.py module), the parameter will be skipped from the analysis. If you are comparing libraries with a different set of analysed parameters (this is the starting point of your analysis), HaSAPPy will premature interrupt raising an issue; in this case check the parameters analysed in the different libraries exploring the library_info.txt file.
```
Type of parameters analysed (mark ‘Y’ or ’N’):
	Independent insertions (I.I.):
	@7F) Y
	Killing insertions (K.I.):
	@7G) Y
	Bias insertions:
	@7H) Y
	Reads:
	@7I) N
```

To summaries the results of multiple parameters and to provide a ranking of the most promising candidates, genes can be sorted by an outlier test (for details on the Outlier analysis refer to HaSAPPy manual). If you are marking ‘Y’, you will activate this analysis and the outlier factor will be available for the following modules.
```
Perform Outlier analysis(mark ‘Y’ or ’N’):
@7J) Y
```

Among the parameters selected for the GroupAnalyis, you can mark those one that you want to use for derivation of the Outlier value. Compile these tasks only if you activated the Outlier option in the previous task
```
Parameters used for Outlier analysis (Fill this part just if marked ‘Y’ to the previously task):
	Type of parameters analysed (mark ‘Y’ or ’N’):
		Independent insertions (I.I.):
		@7K) Y
		Killing insertions (K.I.):
		@7L) Y
		Bias insertions:
		@7M) Y
		Reads:
		@7N) N
```

Outlier analysis compares the ratio of selected parameters between the analysed group respect to the reference group. Fold does not take into account absolute number of insertions present for gene. Therefore, it could happen that genes supported by a little number of insertions gain a high Outlier value through their underrepresentation in the reference. It’s difficult to estimate if this gene could be interesting candidate. You can balance this behavior introducing a Fidelity value that in the percentage that you indicate (0-100) tries to correct outlier outcome with the absolute number of the gene parameters in analysed group (suggested starting fidelity value: 10).An integer number between 0 to 100 is requested
```
Fidelity value for Outlier analysis(Fill this part just if marked ‘Y’ to the 7J task):
Provide a value between 0 to 100 (ex. 10)
@7O) 10
```

If this module is the starting point of the analysis, you should provide information on the name and locations of the library files ( “../../library_dddd-mm-yy/raw/library.GenesData.pkl”) generated by the GeneDefinition.py module. Pay attention to the name correspondence with the one used in section 7C and 7E
```
!!!N.B. Compile the following section just if this is your starting point!!!
How many library do you want to analyse?:
@7P)	
@7P)
…	
Name of the library (Use the same names provided in section 7C and 7E) (add additional lines if necessary):
@7Q)	
@7Q)
…
Location of input file (add additional lines if necessary):
@7R)	
@7R)
…
```

##Section 8: Generate tables
The Tables.py module provides the user to organize calculated data in an Excel table. Selection of parameters and layout of the tables can be customized in the command script. The user has further the possibility to specify parameters for sorting and filtering the data.

Indicate the name of the tables (Excel sheets) that you want to generate. 
```
Table name representation(add additional lines if necessary):
@8A) All_data
@8A) mean
@8A) Fold+stdev
@8A) Score
… 
```

The Table.py module collects user information according 3 parameters:

1. Samples : which group you want to represent. If you selects ‘all’, all the group will be represented (following our example: Unselected, Condition_A, Condition_B).If instead you are providing a specific group name, pay attention to correctly report the group as indicated in section 7.
2. Parameters: which parameter you want to represent for the selected groups among II, KI, Bias, bias_FW, bias_RV, Reads and Score (Outlier analysis). If you mark ‘all’, all available parameters for the indicated group will be presented.
3. Data type: which information of the selected parameter you want to highlight. You can choose between:
  * ‘raw’: provides parameter values of all the replicates composing selected groups
  * ‘mean’: provides parameter values of the average of the replicates composing selected groups
  * ‘stdev’,’fold’ and ’ttest’: provides parameter information of the comparison of the analysed group respect to the reference. They will be skipped from the analysis if the group selected is the reference.

 The ‘all’ code will provide all the possible combination of Data type. The Score parameter doesn’t take any Data type information.

Using these 3 elements you can generate a selector and design your table format. The selector structure to provide is:
```
(Samples, Parameters, Data type)
```
In a table you can provide multiple selecting criteria adding selectors marked with a ‘,’:
```
(Samples_1, Parameters_1, Data type_1) , (Samples_2, Parameters_1, Data type_2)
```
```
Construct table representation using following keys (each new line correspond to a table):
	!!!Read Info file to have detailed informations of how to compile this part!!!
	Samples: all, group name
	Parameters: all, II, KI, Bias, Reads, Score (N.B. Score parameter doesn’t need any 'Data type')
	Data type: all, raw, mean, stdev, fold, ttest
	ex. :  	(all,II,raw),(group1,KI,mean)
		(group1,KI,ttest),(all,Score)
@8B)(all,all,all)
@8B)(all,all,mean)
@8B)(all,all,fold),(all,all,stdev)
@8B)(all,Score)
…
```

User can also decide to select the data to represent and the order applying filters.
Filters definition depend on 3 elements:
1. Keys: a selector as defined in the previous task. Naturally you have to precisely indicate a unique identifier (the ‘all’ possibility can not be applied). The key has not to be present in the generated table, but can refer to any selector available in the analysis
2. Symbols: available symbols can be choose between the one of selection (‘>’, ‘>=’, ‘<’ , ‘<=’ , ‘==’) or the one of ordering (‘ascending’, ‘descending’)
3. Number: if as symbol was picked a selection one, a number must be provided for comparison.
Using these 3 elements you can generate a filter and design your table format. The selector structure to provide is:
```
filter[Keys ,symbols,number]
```
In a table you can provide multiple selecting criteria adding filters separeted with a ‘,’:
```
filter[Keys_1 ,symbols_1,number_1] ’, ‘ filter[Keys_2 ,symbols_2,number_2]
```

Pay attention that HaSAPPy needs to have the same amount of filter lines (i.e. ‘@8C)’) as the number of generated table. If you don’t want to apply any kind of filter for a table, crate an empty filter line
```
Provide a filter parameter to select/sort values displayed (N.B. more than one filter can be defined):
	Keys: as previously defined (N.B. you can not use as parameter ‘all’) 
	Symbols: >, >=, < , <= , == , ascending, descending  
	Number: a float or int value or nothing if (ascending/descending)
	ex. :  	filter[(group2,KI,mean), >, 3.45]
		filter[(group1,KI,mean), ==, 3.45],filter[(group2,Bias,mean), ascending]
@8C) filter[(Condition_A,KI,mean), >, 10]
@8C) filter[(Condition_A,KI,mean), >, 10]
@8C) filter[(Condition_A,KI,mean), >, 10], filter[(Condition_A,Score), descending]
@8C) 
…
```

If this module is the starting point of the analysis, you should provide information on the location of the GroupAnalysis to use for table generation ( “../../Analysis/yyyy-mm-dd /raw/GroupAnalysis.pkl”)

```
!!!N.B. Compile the following section just if this is your starting point!!!
Location of file storing GroupAnalysis informations:
@8D)
```

##Section 9: Design gene insertions
For candidate genes that are of interest visualization of insertion patterns is rendered graphically within gene models by the Design.py module. Representation of gene distribution according to analysed parameter can also be performed. Output is provided as high quality graphics in SVG format.

User can define which typology of plot to generate marking ‘Y’ or ‘N’
```
Type of graph to generate (mark ‘Y’ or ’N’):
	Plot I.I. in gene models
	@9A)
	Plot Gene distribution according analysed parameter:
	@9B)
```

If it has been activated the “Plot I.I. in gene models” option, user should also provide the following information:
```
FOR Plot I.I. in gene models:
```

1. the gene reference file created with the GeneReference_built.py module. The absolute PATH must be provided	
```
	Location of gene reference:
	@9C) Users/User/HaSAPPy/docs/GeneReference_Mouse-MM10.pkl
```

2. The list of genes or chromosome intervals that you are interested to plot. A .svg file will be generate for each of them. If input is a gene name, just write the correct name as present in the gene reference file and in the generated tables. If you are interested to visualize insertions in a specific chromosome interval provide it following this structure:
```
“chromosome_startIV_endIV”.
```

A list of genes/intervals can be provided subdivided by a ‘,’. Spaces between names is managed by HaSAPPy.
```
	Genes list to analyse (also genomic intervals can be provided):
		ex: 	gene1,gene2,gene3
		ex:	chrX_12345619_12456789,chr2_3726189_3726567
	@9D) Xist, Trp53, chrX_12345619_12456789
```

If it has been activated the “Plot Gene distribution according analysed parameters ” option, user should also provide the following information:
```
FOR Plot Gene distribution according analysed parameter:
```

User have the possibility (only if in the GroupAnalysis module the Outlier analysis was performed) to mark into 2 different colors genes with a Score value lower and higher respect a user defined cut-off. Marking ‘Y’, you are activating this function
```
	Do you want to highlight outliers (mark ‘Y’ or ’N’):
	@9E) Y
```

Provide the Score cut-off as an integer
```
	Starting Outlier score to mark as outliers genes (Fill this part just if marked ‘Y’ to the previously task):
	@9F) 40
```

User can also highlight the name of a selection of genes in the plot. Marking ‘Y’, you are activating this function
```
	Do you want to annotate some gene names in the plot (mark ‘Y’ or ’N’):
	@9G) Y
```

The selection of genes to annotate can be defined or providing a gene name list (ex. gene1,gene2,gene3) or a Score value as cut-off.
```
	Genes list to annotate or Outlier starting value:
		ex: 	gene1,gene2,gene3
		ex:	22
	@9H) Xist, Trp53
```
	
If this module is the starting point of the analysis, you should provide information on the location of the GroupAnalysis to use for table generation ( “../../Analysis/yyyy-mm-dd /raw/GroupAnalysis.pkl”)
```
!!!N.B. Compile the following section just if this is your starting point!!!
Location of file storing GroupAnalysis informations:
@9I)
```

##Final remarks
Save the completed `LoadModule.txt` file with a new name and use it as input for runnning the HaSAPPy_start.py module from the command line.

`python HaSAPPy_start.py <path-to-LoadModule.txt>`
